---
title: "舍入误差与Softmax函数"
subtitle: "深度学习-数值计算"
layout: post
author: "Veronica"
header-style: text
tags:
  - 深度学习
---

参考链接：https://blog.csdn.net/lz_peter/article/details/84574716

##### 舍入误差

下溢：接近零的数被四舍五入为0

上溢：大量级的数被近似为$\infty$ 或$-\infty$

##### Softmax函数

又称**归一化指数函数**，对上溢和下溢进行数值稳定

<img src="https://img-blog.csdnimg.cn/20181128162309759.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6X3BldGVy,size_16,color_FFFFFF,t_70" alt="img"  />

Softmax将在负无穷到正无穷上的预测结果按照两步转换：

1）预测的概率为非负数；2）各种预测结果概率之和等于1

转换为概率。

**步骤：**

1）**将预测结果转化为非负数**

将模型的预测结果转化到指数函数上，保证概率的非负性。

2）**各种预测结果概率之和等于1**

将转换后的结果进行归一化处理。

将转化后的结果除以所有转化后结果之和，得到近似的概率。